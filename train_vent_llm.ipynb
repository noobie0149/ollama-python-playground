{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4",
      "authorship_tag": "ABX9TyNM8XnR067a/B/tvutSDA4l",
      "include_colab_link": true
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "view-in-github",
        "colab_type": "text"
      },
      "source": [
        "<a href=\"https://colab.research.google.com/github/noobie0149/ollama-python-playground/blob/main/train_vent_llm.ipynb\" target=\"_parent\"><img src=\"https://colab.research.google.com/assets/colab-badge.svg\" alt=\"Open In Colab\"/></a>"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "6nj6oQSBzCJH"
      },
      "outputs": [],
      "source": [
        "!pip install telethon"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from google.colab import userdata\n",
        "import os\n",
        "gemini_api=userdata.get('gemini_api')\n",
        "telegram_id=userdata.get('telegram_id')\n",
        "telegram_hash=userdata.get('telegram_hash')\n",
        "print(gemini_api)\n",
        "print(telegram_id)\n",
        "print(telegram_hash)"
      ],
      "metadata": {
        "id": "c7gUTREmIyRl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "#\u001bpython\n",
        "# ─── 1. INSTALL DEPENDENCIES ────────────────────────────────────────────────\n",
        "!pip install telethon nest_asyncio\n",
        "\n",
        "# ─── 2. PATCH THE EVENT LOOP FOR JUPYTER/Colab ─────────────────────────────\n",
        "import nest_asyncio\n",
        "nest_asyncio.apply()  # Allows us to await coroutines directly in notebook cells\n",
        "\n",
        "# ─── 3. IMPORT NECESSARY MODULES ───────────────────────────────────────────\n",
        "from datetime import datetime, timedelta, timezone\n",
        "from telethon import TelegramClient\n",
        "from telethon.errors import FloodWaitError\n",
        "import asyncio\n",
        "\n",
        "# ─── 4. CONFIGURE YOUR TELEGRAM API CREDENTIALS ─────────────────────────────\n",
        "#     Replace these with your own values from https://my.telegram.org/apps\n",
        "api_id   = telegram_id                           # Your API ID (integer) from my.telegram.org\n",
        "api_hash = telegram_hash # Your API Hash (string) from my.telegram.org\n",
        "\n",
        "# ─── 5. INITIALIZE A TELETHON CLIENT ────────────────────────────────────────\n",
        "#     This will create (or reuse) 'fetch_channel.session' locally\n",
        "session_name = 'fetch_channel'\n",
        "client = TelegramClient(session_name, api_id, api_hash)  #\n",
        "\n",
        "# ─── 6. DEFINE THE ASYNC FUNCTION TO FETCH MESSAGES ────────────────────────\n",
        "async def fetch_last_10_days(channel_username: str):\n",
        "    \"\"\"\n",
        "    Connect to a public channel (by username, no '@') and return a list of\n",
        "    all Message objects from the last 10 days (UTC).\n",
        "    \"\"\"\n",
        "    # 6.1 START/LOGIN (will prompt on first run, reuse session thereafter)\n",
        "    await client.start()  #\n",
        "\n",
        "    # 6.2 RESOLVE CHANNEL ENTITY:\n",
        "    #     Converts 'python_engineers' into the underlying Channel object\n",
        "    channel_entity = await client.get_entity(channel_username)  #\n",
        "\n",
        "    # 6.3 COMPUTE THE \"10 DAYS AGO\" THRESHOLD IN UTC\n",
        "    now_utc      = datetime.now(timezone.utc)\n",
        "    ten_days_ago = now_utc - timedelta(days=10)\n",
        "\n",
        "    # 6.4 ITERATE OVER MESSAGES (newest → oldest), STOP WHEN OLDER THAN THRESHOLD\n",
        "    recent_messages = []\n",
        "    try:\n",
        "        async for message in client.iter_messages(channel_entity, limit=None):\n",
        "            # message.date is a timezone‐aware UTC datetime\n",
        "            if message.date < ten_days_ago:\n",
        "                break\n",
        "            recent_messages.append(message)\n",
        "\n",
        "    except FloodWaitError as e:\n",
        "        # If Telegram rate‐limits us (“GetHistory” flood‐wait), Telethon raises this.\n",
        "        print(f\"FloodWaitError: must wait {e.seconds} seconds.\")  #\n",
        "        await asyncio.sleep(e.seconds)  # Pause before (optionally) retrying\n",
        "\n",
        "    finally:\n",
        "        # 6.5 DISCONNECT WHEN DONE\n",
        "        await client.disconnect()\n",
        "\n",
        "    return recent_messages\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qo-D4E37IZvp",
        "outputId": "4362e26f-b30a-4661-d880-64827d534989"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: telethon in /usr/local/lib/python3.11/dist-packages (1.40.0)\n",
            "Requirement already satisfied: nest_asyncio in /usr/local/lib/python3.11/dist-packages (1.6.0)\n",
            "Requirement already satisfied: pyaes in /usr/local/lib/python3.11/dist-packages (from telethon) (1.6.1)\n",
            "Requirement already satisfied: rsa in /usr/local/lib/python3.11/dist-packages (from telethon) (4.9.1)\n",
            "Requirement already satisfied: pyasn1>=0.1.3 in /usr/local/lib/python3.11/dist-packages (from rsa->telethon) (0.6.1)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "#\u001bpython\n",
        "# ─── 1. SET YOUR TARGET CHANNEL USERNAME (no '@') ───────────────────────────\n",
        "channel_username = 'TheReporterEthiopia'  # e.g., for https://t.me/python_engineers\n",
        "\n",
        "# ─── 2. CALL THE COROUTINE DIRECTLY (because nest_asyncio is applied) ────────\n",
        "messages = await fetch_last_10_days(channel_username)\n",
        "\n",
        "# ─── 3. OPEN A TEXT FILE TO WRITE ALL MESSAGES ──────────────────────────────\n",
        "#     Each line will have: [YYYY-MM-DD HH:MM:SS UTC] <full_text_or_[No text]>\n",
        "output_filename = 'last_10_days.txt'\n",
        "with open(output_filename, 'w', encoding='utf-8') as f:\n",
        "    header = f\"Messages from the last 10 days in @{channel_username} (total: {len(messages)})\\n\"\n",
        "    f.write(header)\n",
        "    f.write(\"=\" * len(header) + \"\\n\\n\")\n",
        "\n",
        "    for msg in messages:\n",
        "        # Format timestamp\n",
        "        ts = msg.date.strftime('%Y-%m-%d %H:%M:%S UTC')\n",
        "        # Use the full text if available; otherwise indicate “[No text]”\n",
        "        text_body = msg.text if msg.text else \"[No text]\"\n",
        "\n",
        "        # Write to file\n",
        "        f.write(f\"[{ts}] {text_body}\\n\")\n",
        "        f.write(\"-\" * 80 + \"\\n\")\n",
        "\n",
        "# ─── 4. CONFIRMATION PRINTOUT ───────────────────────────────────────────────\n",
        "print(f\"Wrote {len(messages)} messages to '{output_filename}'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "a-7HusNzIj-R",
        "outputId": "76d27eb6-68a7-4636-a5a6-b0501cbe6364"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Wrote 49 messages to 'last_10_days.txt'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# format_telegram_posts.py\n",
        "\n",
        "from google import genai\n",
        "import os\n",
        "\n",
        "# ─── Step 1: CONFIGURE YOUR GEMINI CLIENT ───────────────────────────────────\n",
        "# Replace the string below with your actual Gemini/Google Gen AI API key.\n",
        "# (This matches how \"transcript_to_csv.py\" instantiates the client.)\n",
        "client = genai.Client(api_key=gemini_api)  # :contentReference[oaicite:0]{index=0}\n",
        "\n",
        "# ─── Step 2: CHOOSE A MODEL NAME ─────────────────────────────────────────────\n",
        "# You can swap this out for any Gemini variant you have access to (e.g., gemini-2.5-flash-preview-04-17).\n",
        "MODEL_NAME     = \"gemini-2.5-flash-preview-04-17\"   # :contentReference[oaicite:1]{index=1}\n",
        "\n",
        "# ─── Step 3: DEFINE INPUT/OUTPUT FILES ───────────────────────────────────────\n",
        "RAW_FILE       = \"last_10_days.txt\"                # Contains the raw, 10‐day channel dump\n",
        "FORMATTED_FILE = \"formatted_last_10_days.txt\"      # Where Gemini’s output will be saved\n",
        "\n",
        "def label_posts(raw_text: str) -> str:\n",
        "    \"\"\"\n",
        "    Build a single prompt (system instructions + raw_text) and call Gemini\n",
        "    to reformat each Telegram post into a bullet point that preserves the UTC timestamp.\n",
        "\n",
        "    Returns:\n",
        "        str: The full text response from Gemini.\n",
        "    \"\"\"\n",
        "    # ─── 3.1: SYSTEM PROMPT (INSTRUCTIONS TO GEMINI) ───────────────────────────\n",
        "    system_prompt = (\n",
        "        \"You are a helpful assistant.  Below are all Telegram‐channel posts from the last 10 days.  \"\n",
        "        \"Please reformat each post into a bullet point, preserving the original UTC timestamp and text.  \"\n",
        "        \"If a post has no text (e.g., only media), write “[No text]” instead.  Output plain text, \"\n",
        "        \"one bullet per line, in this exact form:\\n\\n\"\n",
        "        \"    - [YYYY-MM-DD HH:MM:SS UTC] <message text>\\n\\n\"\n",
        "        \"Separate each bullet with a blank line.\"\n",
        "    )\n",
        "    # ─── 3.2: CONCATENATE SYSTEM PROMPT + RAW TEXT ──────────────────────────────\n",
        "    full_prompt = f\"{system_prompt}\\n\\n─── RAW MESSAGES START BELOW ───\\n\\n{raw_text}\"\n",
        "\n",
        "    # ─── 3.3: CALL GEMINI VIA genai.Client ────────────────────────────────────\n",
        "    # This mirrors how your \"transcript_to_csv.py\" calls client.models.generate_content(...)\n",
        "    response = client.models.generate_content(\n",
        "        model=MODEL_NAME,\n",
        "        contents=full_prompt\n",
        "    )\n",
        "    return response.text  # Gemini’s formatted reply\n",
        "\n",
        "\n",
        "if __name__ == \"__main__\":\n",
        "    # ─── Step 4: READ THE RAW FILE ─────────────────────────────────────────────\n",
        "    if not os.path.exists(RAW_FILE):\n",
        "        print(f\"ERROR: Cannot find '{RAW_FILE}'. Make sure you run the Telegram‐fetch step first.\")\n",
        "        exit(1)\n",
        "\n",
        "    with open(RAW_FILE, 'r', encoding='utf-8') as infile:\n",
        "        raw_data = infile.read()\n",
        "\n",
        "    print(f\"Read {len(raw_data)} characters from '{RAW_FILE}'. Beginning Gemini call...\")\n",
        "\n",
        "    # ─── Step 5: SEND TO GEMINI FOR FORMATTING ─────────────────────────────────\n",
        "    formatted_output = label_posts(raw_data)\n",
        "\n",
        "    # ─── Step 6: WRITE GEMINI’S RESPONSE ───────────────────────────────────────\n",
        "    with open(FORMATTED_FILE, 'w', encoding='utf-8') as outfile:\n",
        "        outfile.write(formatted_output)\n",
        "\n",
        "    print(f\"Gemini’s formatted result has been written to '{FORMATTED_FILE}'.\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9ZiFKUnPIqeP",
        "outputId": "253a59ba-ce41-492a-b24f-8fa1f617f978"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Read 32140 characters from 'last_10_days.txt'. Beginning Gemini call...\n",
            "Gemini’s formatted result has been written to 'formatted_last_10_days.txt'.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [],
      "metadata": {
        "id": "rRdMXX15zCXW"
      }
    }
  ]
}